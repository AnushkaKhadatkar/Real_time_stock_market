# Real-Time Stock Market Data Pipeline

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![Kafka](https://img.shields.io/badge/Kafka-Streaming-red.svg)
![Snowflake](https://img.shields.io/badge/Snowflake-Cloud%20DW-29B5E8.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

An end-to-end real-time data engineering pipeline built with the Modern Data Stack. This project captures live stock market data from Finnhub API, streams it through Kafka, transforms it in Snowflake using DBT, and delivers analytics via Power BI dashboards.

ğŸ—ï¸ ## Architecture

![Architecture](Architecture.png)

The pipeline implements a medallion architecture (Bronze â†’ Silver â†’ Gold) with the following data flow:

1. **Ingestion**: Python producer fetches live stock data from Finnhub API
2. **Streaming**: Apache Kafka streams data in real-time with 3 partitions
3. **Storage**: Kafka consumer stores raw data in MinIO (S3-compatible storage)
4. **Orchestration**: Airflow DAG loads data from MinIO to Snowflake every minute
5. **Transformation**: DBT transforms data across Bronze, Silver, and Gold layers in Snowflake
6. **Visualization**: Power BI connects to Gold layer for interactive dashboards

ğŸ§° ## Tech Stack

- **Data Source**: Finnhub API (live stock market data)
- **Streaming**: Apache Kafka + Zookeeper
- **Storage**: MinIO (S3-compatible object storage)
- **Orchestration**: Apache Airflow + PostgreSQL
- **Data Warehouse**: Snowflake
- **Transformation**: DBT (Data Build Tool)
- **Visualization**: Power BI
- **Language**: Python 3.8+
- **Deployment**: Docker + Docker Compose

ğŸ§  ## Features

- âœ… Real-time stock market data streaming (not simulated)
- âœ… Fault-tolerant message processing with Kafka
- âœ… Automated ETL orchestration with Airflow
- âœ… Multi-layer data transformations (Bronze â†’ Silver â†’ Gold)
- âœ… Cloud-native data warehousing with Snowflake
- âœ… Interactive dashboards with candlestick charts, KPIs, and trend analysis
- âœ… Fully containerized architecture with Docker
- âœ… Scalable design with horizontal scaling capabilities

ğŸ“‚ ## Project Structure

```
real-time-stocks-pipeline/
â”œâ”€â”€ infra/
â”‚   â””â”€â”€ docker-compose.yml          # Docker services configuration
â”œâ”€â”€ producer/
â”‚   â””â”€â”€ producer.py                 # Kafka producer (Finnhub API)
â”œâ”€â”€ consumer/
â”‚   â””â”€â”€ consumer.py                 # Kafka consumer (MinIO sink)
â”œâ”€â”€ dbt_stocks/
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ bronze/                 # Raw staging layer
â”‚       â”œâ”€â”€ silver/                 # Cleaned data layer
â”‚       â””â”€â”€ gold/                   # Analytics layer
â”œâ”€â”€ dag/
â”‚   â””â”€â”€ minio_to_snowflake.py       # Airflow DAG
â””â”€â”€ requirements.txt
```

ğŸš€ ## Getting Started

### Prerequisites

- Docker Desktop
- Python 3.8+
- Snowflake account
- Finnhub API key (free tier available)

### Installation

1. Clone the repository
2. Set up virtual environment and install dependencies
3. Configure `docker-compose.yml` and start services
4. Initialize Airflow and create admin user
5. Create Kafka topic `stock_quotes` with 3 partitions
6. Set up Snowflake database, schema, and warehouse
7. Configure DBT with Snowflake credentials
8. Update producer script with Finnhub API key

### Running the Pipeline

1. **Start Producer**: Run `producer.py` to fetch and stream stock data
2. **Start Consumer**: Run `consumer.py` to consume and store data in MinIO
3. **Enable Airflow DAG**: Access Airflow UI and enable `minio_to_snowflake` DAG
4. **Run DBT**: Execute `dbt run` to create Bronze, Silver, and Gold tables
5. **Connect Power BI**: Link to Snowflake Gold layer and build dashboards

ğŸª™ ## Data Layers

- ğŸ¥‰ **Bronze**: Raw data as ingested from Kafka/MinIO
- ğŸ¥ˆ **Silver**: Cleaned, validated, and deduplicated data
- ğŸ¥‡ **Gold**: Analytics-ready models (candlestick, KPIs, treechart)

ğŸ”Œ ## Docker Services

| Service | Port | Description |
|---------|------|-------------|
| Kafka | 9092 | Message broker |
| Kafdrop | 9000 | Kafka UI |
| MinIO | 9001 | Object storage console |
| Airflow | 8080 | Workflow UI |
| PostgreSQL | 5432 | Airflow metadata |

ğŸ§‘â€ğŸ’» ## Author

**Anushka Khadatkar**

---

â¤ï¸ Made with love for Data Engineering
